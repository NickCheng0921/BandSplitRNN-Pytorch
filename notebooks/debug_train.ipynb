{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b583cc33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-19T15:35:20.308315Z",
     "start_time": "2023-02-19T15:35:19.252614Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from hydra import compose, initialize\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from train import initialize_loaders, initialize_model, initialize_featurizer\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c77f175",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-19T15:35:20.601045Z",
     "start_time": "2023-02-19T15:35:20.310168Z"
    }
   },
   "outputs": [],
   "source": [
    "with initialize(version_base=None, config_path=\"../src/conf\", job_name=\"test_app\"):\n",
    "    cfg = compose(config_name=\"config\")\n",
    "#     print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21fa0554",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-19T15:35:38.523781Z",
     "start_time": "2023-02-19T15:35:38.515200Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_loader, val_loader = initialize_loaders(cfg)\n",
    "# featurizer, inverse_featurizer = initialize_featurizer(cfg)\n",
    "# model, opt, sch = initialize_model(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe5f5969",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-19T15:36:59.384051Z",
     "start_time": "2023-02-19T15:36:59.373648Z"
    }
   },
   "outputs": [],
   "source": [
    "from data import SAD\n",
    "import musdb\n",
    "import torch\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "855dd122",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-19T15:37:00.706467Z",
     "start_time": "2023-02-19T15:37:00.689541Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_save_line(\n",
    "    track_name: str, \n",
    "    start_indices: torch.Tensor, \n",
    "    window_size: int\n",
    ") -> Iterable[str]:\n",
    "    for i in start_indices:\n",
    "        save_line = f\"{track_name}\\t{i}\\t{i + window_size}\\n\"\n",
    "        yield save_line\n",
    "        \n",
    "        \n",
    "def save_to_file(\n",
    "    file_path: str,\n",
    "    target: str,\n",
    "    sad: SAD, \n",
    "):\n",
    "    with open(file_path, 'w') as wf:\n",
    "        for track in tqdm(db):\n",
    "            y = track.targets[target].audio.T\n",
    "            y = torch.tensor(\n",
    "                y, dtype=torch.float32\n",
    "            )\n",
    "            indices = sad.calculate_salient_indices(y)\n",
    "            for l in prepare_save_line(track.name, indices, sad.window_size):\n",
    "                wf.write(l)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5dd79696",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-19T15:43:48.834632Z",
     "start_time": "2023-02-19T15:43:48.825339Z"
    }
   },
   "outputs": [],
   "source": [
    "targets = ['vocals']\n",
    "db_dir = '../../../datasets/musdb18hq'\n",
    "directory = Path('../src/files/')\n",
    "subset = 'train' # 'test'\n",
    "split = 'train' # 'valid'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "716fc0b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-19T15:43:54.906263Z",
     "start_time": "2023-02-19T15:43:50.710143Z"
    }
   },
   "outputs": [],
   "source": [
    "db = musdb.DB(\n",
    "    root=db_dir,\n",
    "    download=False,\n",
    "    subsets=subset,\n",
    "    split=split,\n",
    "    is_wav=True\n",
    ")\n",
    "sad = SAD(**cfg.sad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "579a1319",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-19T15:44:19.410539Z",
     "start_time": "2023-02-19T15:44:01.861345Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 26/86 [00:17<00:40,  1.49it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[18], line 8\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m subset \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m      7\u001B[0m     file_path \u001B[38;5;241m=\u001B[39m directory \u001B[38;5;241m/\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtarget\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_test.txt\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 8\u001B[0m \u001B[43msave_to_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msad\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[8], line 22\u001B[0m, in \u001B[0;36msave_to_file\u001B[0;34m(file_path, target, sad)\u001B[0m\n\u001B[1;32m     18\u001B[0m y \u001B[38;5;241m=\u001B[39m track\u001B[38;5;241m.\u001B[39mtargets[target]\u001B[38;5;241m.\u001B[39maudio\u001B[38;5;241m.\u001B[39mT\n\u001B[1;32m     19\u001B[0m y \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(\n\u001B[1;32m     20\u001B[0m     y, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32\n\u001B[1;32m     21\u001B[0m )\n\u001B[0;32m---> 22\u001B[0m indices \u001B[38;5;241m=\u001B[39m \u001B[43msad\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcalculate_salient_indices\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m prepare_save_line(track\u001B[38;5;241m.\u001B[39mname, indices, sad\u001B[38;5;241m.\u001B[39mwindow_size):\n\u001B[1;32m     24\u001B[0m     wf\u001B[38;5;241m.\u001B[39mwrite(l)\n",
      "File \u001B[0;32m~/PythonProjects/projects/SourceSeparationBandSplitRNN/notebooks/../src/data/preprocessing.py:105\u001B[0m, in \u001B[0;36mSAD.calculate_salient_indices\u001B[0;34m(self, y)\u001B[0m\n\u001B[1;32m     98\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcalculate_salient_indices\u001B[39m(\n\u001B[1;32m     99\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    100\u001B[0m         y: torch\u001B[38;5;241m.\u001B[39mTensor\n\u001B[1;32m    101\u001B[0m ):\n\u001B[1;32m    102\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    103\u001B[0m \u001B[38;5;124;03m    Returns start indices of salient regions of audio\u001B[39;00m\n\u001B[1;32m    104\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 105\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchunk\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    106\u001B[0m     rms \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcalculate_rms(y)\n\u001B[1;32m    107\u001B[0m     mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcalculate_thresholds(rms)\n",
      "File \u001B[0;32m~/PythonProjects/projects/SourceSeparationBandSplitRNN/notebooks/../src/data/preprocessing.py:39\u001B[0m, in \u001B[0;36mSAD.chunk\u001B[0;34m(self, y)\u001B[0m\n\u001B[1;32m     37\u001B[0m y \u001B[38;5;241m=\u001B[39m y\u001B[38;5;241m.\u001B[39munfold(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwindow_size, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstep_size)\n\u001B[1;32m     38\u001B[0m y \u001B[38;5;241m=\u001B[39m y\u001B[38;5;241m.\u001B[39mchunk(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_chunks_per_segment, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m---> 39\u001B[0m y \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstack\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m y\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for target in targets:\n",
    "    if subset == split == 'train':\n",
    "        file_path = directory / f\"{target}_train.txt\"\n",
    "    elif subset == 'train' and split == 'valid':\n",
    "        file_path = directory / f\"{target}_valid.txt\"\n",
    "    elif subset == 'test':\n",
    "        file_path = directory / f\"{target}_test.txt\"\n",
    "    save_to_file(file_path, target, sad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36d265f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-19T14:03:40.303049Z",
     "start_time": "2023-02-19T14:03:40.297737Z"
    }
   },
   "outputs": [],
   "source": [
    "class PLModel(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self, \n",
    "        model: nn.Module,\n",
    "        featurizer: nn.Module,\n",
    "        inverse_featurizer: nn.Module,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # featurizers \n",
    "        self.featurizer = featurizer\n",
    "        self.inverse_featurizer = inverse_featurizer\n",
    "                \n",
    "        # model\n",
    "        self.model = model\n",
    "        \n",
    "        # losses\n",
    "        self.mae_specR = nn.L1Loss() \n",
    "        self.mae_specI = nn.L1Loss() \n",
    "        self.mae_time = nn.L1Loss() \n",
    "        \n",
    "        # opts\n",
    "        \n",
    "    \n",
    "    def on_after_batch_transfer(\n",
    "        self, batch, dataloader_idx\n",
    "    ):\n",
    "        for k in batch:\n",
    "            batch[k] = self.featurizer(batch[k])\n",
    "        return batch\n",
    "    \n",
    "    def training_step(\n",
    "        self, batch, batch_idx\n",
    "    ):\n",
    "        mix, tgt = batch['mix'], batch['tgt']\n",
    "        mix = self.model(mix)\n",
    "        loss = self.loss(mix, tgt)\n",
    "        return loss\n",
    "    \n",
    "    def loss(self, mix, tgt):\n",
    "        # frequence domain\n",
    "        lossR = self.mae_specR(mix.real, tgt.real)\n",
    "        lossI = self.mae_specI(mix.imag, tgt.imag)\n",
    "        \n",
    "        # time domain\n",
    "        mix = self.inverse_featurizer(mix)\n",
    "        tgt = self.inverse_featurizer(tgt)\n",
    "        lossT = self.mae_time(mix, tgt) \n",
    "        \n",
    "        # total\n",
    "        loss = lossR + lossI + lossT\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(\n",
    "            self.parameters(), \n",
    "            lr=1e-3\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47720803",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-19T14:03:40.390931Z",
     "start_time": "2023-02-19T14:03:40.304944Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/amanturamatov/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
     ]
    }
   ],
   "source": [
    "plmodel = PLModel(\n",
    "    model, \n",
    "    featurizer,\n",
    "    inverse_featurizer\n",
    ")\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"cpu\",\n",
    "    devices=1,\n",
    "    fast_dev_run=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18bd2557",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-19T14:03:45.102660Z",
     "start_time": "2023-02-19T14:03:40.504835Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name               | Type               | Params\n",
      "----------------------------------------------------------\n",
      "0 | featurizer         | Spectrogram        | 0     \n",
      "1 | inverse_featurizer | InverseSpectrogram | 0     \n",
      "2 | model              | BandSplitRNN       | 11.7 M\n",
      "3 | mae_specR          | L1Loss             | 0     \n",
      "4 | mae_specI          | L1Loss             | 0     \n",
      "5 | mae_time           | L1Loss             | 0     \n",
      "----------------------------------------------------------\n",
      "11.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.7 M    Total params\n",
      "46.687    Total estimated model params size (MB)\n",
      "/Users/amanturamatov/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff6311210e8d43e79a71b94e1cb93ee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Users/amanturamatov/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/Users/amanturamatov/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Users/amanturamatov/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Users/amanturamatov/PythonProjects/projects/SourceSeparationBandSplitRNN/notebooks/../src/data/dataset.py\", line 67, in __getitem__\n    mix, tgt = self.prepare_fragments(\n  File \"/Users/amanturamatov/PythonProjects/projects/SourceSeparationBandSplitRNN/notebooks/../src/data/dataset.py\", line 54, in prepare_fragments\n    tgt_frags, mask = self.sad(tgt_audio)\n  File \"/Users/amanturamatov/PythonProjects/projects/SourceSeparationBandSplitRNN/notebooks/../src/data/preprocessing.py\", line 95, in __call__\n    y_salient = self.calculate_salient(y, segment_saliency_mask)\n  File \"/Users/amanturamatov/PythonProjects/projects/SourceSeparationBandSplitRNN/notebooks/../src/data/preprocessing.py\", line 73, in calculate_salient\n    y = y[:, mask, ...].view(C, D1, D2*D3)\nRuntimeError: shape '[2, 78, 264600]' is invalid for input of size 31752000\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mplmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:608\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[1;32m    606\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_unwrap_optimized(model)\n\u001B[1;32m    607\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39m_lightning_module \u001B[38;5;241m=\u001B[39m model\n\u001B[0;32m--> 608\u001B[0m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    609\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\n\u001B[1;32m    610\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:38\u001B[0m, in \u001B[0;36m_call_and_handle_interrupt\u001B[0;34m(trainer, trainer_fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m     36\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher\u001B[38;5;241m.\u001B[39mlaunch(trainer_fn, \u001B[38;5;241m*\u001B[39margs, trainer\u001B[38;5;241m=\u001B[39mtrainer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     37\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 38\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrainer_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n\u001B[1;32m     41\u001B[0m     trainer\u001B[38;5;241m.\u001B[39m_call_teardown_hook()\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:650\u001B[0m, in \u001B[0;36mTrainer._fit_impl\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[1;32m    643\u001B[0m ckpt_path \u001B[38;5;241m=\u001B[39m ckpt_path \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresume_from_checkpoint\n\u001B[1;32m    644\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ckpt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39m_set_ckpt_path(\n\u001B[1;32m    645\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn,\n\u001B[1;32m    646\u001B[0m     ckpt_path,  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[1;32m    647\u001B[0m     model_provided\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    648\u001B[0m     model_connected\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    649\u001B[0m )\n\u001B[0;32m--> 650\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    652\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstopped\n\u001B[1;32m    653\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1112\u001B[0m, in \u001B[0;36mTrainer._run\u001B[0;34m(self, model, ckpt_path)\u001B[0m\n\u001B[1;32m   1108\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39mrestore_training_state()\n\u001B[1;32m   1110\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39mresume_end()\n\u001B[0;32m-> 1112\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_stage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1114\u001B[0m log\u001B[38;5;241m.\u001B[39mdetail(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: trainer tearing down\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1115\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_teardown()\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1191\u001B[0m, in \u001B[0;36mTrainer._run_stage\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1189\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredicting:\n\u001B[1;32m   1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_predict()\n\u001B[0;32m-> 1191\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1214\u001B[0m, in \u001B[0;36mTrainer._run_train\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1211\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit_loop\u001B[38;5;241m.\u001B[39mtrainer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\n\u001B[1;32m   1213\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mset_detect_anomaly(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_detect_anomaly):\n\u001B[0;32m-> 1214\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py:199\u001B[0m, in \u001B[0;36mLoop.run\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    197\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    198\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_start(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 199\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madvance\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    200\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_end()\n\u001B[1;32m    201\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_restarting \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:267\u001B[0m, in \u001B[0;36mFitLoop.advance\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    265\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_fetcher\u001B[38;5;241m.\u001B[39msetup(dataloader, batch_to_device\u001B[38;5;241m=\u001B[39mbatch_to_device)\n\u001B[1;32m    266\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_training_epoch\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 267\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mepoch_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_data_fetcher\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py:199\u001B[0m, in \u001B[0;36mLoop.run\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    197\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    198\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_start(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 199\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madvance\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    200\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_end()\n\u001B[1;32m    201\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_restarting \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py:187\u001B[0m, in \u001B[0;36mTrainingEpochLoop.advance\u001B[0;34m(self, data_fetcher)\u001B[0m\n\u001B[1;32m    185\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_fetcher, DataLoaderIterDataFetcher):\n\u001B[1;32m    186\u001B[0m     batch_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_idx \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m--> 187\u001B[0m     batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdata_fetcher\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    188\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    189\u001B[0m     batch_idx, batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(data_fetcher)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/pytorch_lightning/utilities/fetching.py:184\u001B[0m, in \u001B[0;36mAbstractDataFetcher.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    183\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__next__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m--> 184\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetching_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/pytorch_lightning/utilities/fetching.py:265\u001B[0m, in \u001B[0;36mDataFetcher.fetching_function\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    262\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdone:\n\u001B[1;32m    263\u001B[0m     \u001B[38;5;66;03m# this will run only when no pre-fetching was done.\u001B[39;00m\n\u001B[1;32m    264\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 265\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fetch_next_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataloader_iter\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    266\u001B[0m         \u001B[38;5;66;03m# consume the batch we just fetched\u001B[39;00m\n\u001B[1;32m    267\u001B[0m         batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatches\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/pytorch_lightning/utilities/fetching.py:280\u001B[0m, in \u001B[0;36mDataFetcher._fetch_next_batch\u001B[0;34m(self, iterator)\u001B[0m\n\u001B[1;32m    278\u001B[0m start_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_fetch_start()\n\u001B[1;32m    279\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 280\u001B[0m     batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    281\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    282\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stop_profiler()\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/pytorch_lightning/trainer/supporters.py:569\u001B[0m, in \u001B[0;36mCombinedLoaderIterator.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    563\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__next__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    564\u001B[0m     \u001B[38;5;124;03m\"\"\"Fetches the next batch from multiple data loaders.\u001B[39;00m\n\u001B[1;32m    565\u001B[0m \n\u001B[1;32m    566\u001B[0m \u001B[38;5;124;03m    Returns:\u001B[39;00m\n\u001B[1;32m    567\u001B[0m \u001B[38;5;124;03m        a collections of batch data\u001B[39;00m\n\u001B[1;32m    568\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 569\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest_next_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloader_iters\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/pytorch_lightning/trainer/supporters.py:581\u001B[0m, in \u001B[0;36mCombinedLoaderIterator.request_next_batch\u001B[0;34m(loader_iters)\u001B[0m\n\u001B[1;32m    571\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[1;32m    572\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrequest_next_batch\u001B[39m(loader_iters: Union[Iterator, Sequence, Mapping]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    573\u001B[0m     \u001B[38;5;124;03m\"\"\"Return the batch of data from multiple iterators.\u001B[39;00m\n\u001B[1;32m    574\u001B[0m \n\u001B[1;32m    575\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    579\u001B[0m \u001B[38;5;124;03m        Any: a collections of batch data\u001B[39;00m\n\u001B[1;32m    580\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 581\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mapply_to_collection\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloader_iters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mIterator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/lightning_utilities/core/apply_func.py:47\u001B[0m, in \u001B[0;36mapply_to_collection\u001B[0;34m(data, dtype, function, wrong_dtype, include_none, *args, **kwargs)\u001B[0m\n\u001B[1;32m     45\u001B[0m \u001B[38;5;66;03m# Breaking condition\u001B[39;00m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, dtype) \u001B[38;5;129;01mand\u001B[39;00m (wrong_dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, wrong_dtype)):\n\u001B[0;32m---> 47\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m elem_type \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtype\u001B[39m(data)\n\u001B[1;32m     51\u001B[0m \u001B[38;5;66;03m# Recursively apply to collection items\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    625\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    626\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    627\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 628\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    629\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    630\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    631\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    632\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1333\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1331\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1332\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_task_info[idx]\n\u001B[0;32m-> 1333\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_process_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1359\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._process_data\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m   1357\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_try_put_index()\n\u001B[1;32m   1358\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, ExceptionWrapper):\n\u001B[0;32m-> 1359\u001B[0m     \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreraise\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1360\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/torch/_utils.py:543\u001B[0m, in \u001B[0;36mExceptionWrapper.reraise\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    539\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m    540\u001B[0m     \u001B[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001B[39;00m\n\u001B[1;32m    541\u001B[0m     \u001B[38;5;66;03m# instantiate since we don't know how to\u001B[39;00m\n\u001B[1;32m    542\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m--> 543\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exception\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Users/amanturamatov/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/Users/amanturamatov/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Users/amanturamatov/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Users/amanturamatov/PythonProjects/projects/SourceSeparationBandSplitRNN/notebooks/../src/data/dataset.py\", line 67, in __getitem__\n    mix, tgt = self.prepare_fragments(\n  File \"/Users/amanturamatov/PythonProjects/projects/SourceSeparationBandSplitRNN/notebooks/../src/data/dataset.py\", line 54, in prepare_fragments\n    tgt_frags, mask = self.sad(tgt_audio)\n  File \"/Users/amanturamatov/PythonProjects/projects/SourceSeparationBandSplitRNN/notebooks/../src/data/preprocessing.py\", line 95, in __call__\n    y_salient = self.calculate_salient(y, segment_saliency_mask)\n  File \"/Users/amanturamatov/PythonProjects/projects/SourceSeparationBandSplitRNN/notebooks/../src/data/preprocessing.py\", line 73, in calculate_salient\n    y = y[:, mask, ...].view(C, D1, D2*D3)\nRuntimeError: shape '[2, 78, 264600]' is invalid for input of size 31752000\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(\n",
    "    plmodel, \n",
    "    train_dataloaders=train_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5bbc06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
