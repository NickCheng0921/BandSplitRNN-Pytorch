{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a3769b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-19T18:51:34.309846Z",
     "start_time": "2023-02-19T18:51:34.270007Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b583cc33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-19T18:51:43.014118Z",
     "start_time": "2023-02-19T18:51:42.929935Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 7\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnn\u001B[39;00m\n\u001B[0;32m----> 7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtrain\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m initialize_loaders, initialize_model, initialize_featurizer\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtqdm\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tqdm\n",
      "File \u001B[0;32m~/PythonProjects/projects/SourceSeparationBandSplitRNN/src/train.py:9\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnn\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DataLoader\n\u001B[0;32m----> 9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SourceSeparationDataset, collate_fn\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmodel\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BandSplitRNN\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Tuple\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'data'"
     ]
    }
   ],
   "source": [
    "from hydra import compose, initialize\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from src.train import initialize_loaders, initialize_model, initialize_featurizer\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c77f175",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-19T18:42:39.375360Z",
     "start_time": "2023-02-19T18:42:39.267448Z"
    }
   },
   "outputs": [],
   "source": [
    "with initialize(version_base=None, config_path=\"../src/conf\", job_name=\"test_app\"):\n",
    "    cfg = compose(config_name=\"config\")\n",
    "#     print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21fa0554",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-19T18:42:39.749103Z",
     "start_time": "2023-02-19T18:42:39.706315Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m train_loader, val_loader \u001B[38;5;241m=\u001B[39m \u001B[43minitialize_loaders\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcfg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m featurizer, inverse_featurizer \u001B[38;5;241m=\u001B[39m initialize_featurizer(cfg)\n\u001B[1;32m      3\u001B[0m model, opt, sch \u001B[38;5;241m=\u001B[39m initialize_model(cfg)\n",
      "File \u001B[0;32m~/PythonProjects/projects/SourceSeparationBandSplitRNN/notebooks/../src/train.py:20\u001B[0m, in \u001B[0;36minitialize_loaders\u001B[0;34m(cfg)\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minitialize_loaders\u001B[39m(cfg: DictConfig) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[DataLoader, DataLoader]:\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;124;03m    Initializes train and validation dataloaders from configuration file.\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 20\u001B[0m     train_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mSourceSeparationDataset\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcfg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     23\u001B[0m     val_dataset \u001B[38;5;241m=\u001B[39m SourceSeparationDataset(\n\u001B[1;32m     24\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcfg\u001B[38;5;241m.\u001B[39mval_dataset,\n\u001B[1;32m     25\u001B[0m     )\n\u001B[1;32m     26\u001B[0m     train_loader \u001B[38;5;241m=\u001B[39m DataLoader(\n\u001B[1;32m     27\u001B[0m         train_dataset,\n\u001B[1;32m     28\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcfg\u001B[38;5;241m.\u001B[39mtrain_loader,\n\u001B[1;32m     29\u001B[0m         collate_fn\u001B[38;5;241m=\u001B[39mcollate_fn\n\u001B[1;32m     30\u001B[0m     )\n",
      "File \u001B[0;32m~/PythonProjects/projects/SourceSeparationBandSplitRNN/notebooks/../src/data/dataset.py:34\u001B[0m, in \u001B[0;36mSourceSeparationDataset.__init__\u001B[0;34m(self, file_dir, txt_dir, txt_path, target, is_mono, mode)\u001B[0m\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou need to specify either \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtxt_path\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m or \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtxt_dir\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_mono \u001B[38;5;241m=\u001B[39m is_mono\n\u001B[0;32m---> 34\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfilelist, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfilename2label \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_filelist\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PythonProjects/projects/SourceSeparationBandSplitRNN/notebooks/../src/data/dataset.py:44\u001B[0m, in \u001B[0;36mSourceSeparationDataset.get_filelist\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     42\u001B[0m i \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtxt_path, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mreadlines():\n\u001B[0;32m---> 44\u001B[0m     file_name, start_idx, end_idx \u001B[38;5;241m=\u001B[39m line\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/t\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     45\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m file_name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m filename2label:\n\u001B[1;32m     46\u001B[0m         filename2label[file_name] \u001B[38;5;241m=\u001B[39m i\n",
      "\u001B[0;31mValueError\u001B[0m: not enough values to unpack (expected 3, got 1)"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = initialize_loaders(cfg)\n",
    "featurizer, inverse_featurizer = initialize_featurizer(cfg)\n",
    "model, opt, sch = initialize_model(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36d265f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-19T14:03:40.303049Z",
     "start_time": "2023-02-19T14:03:40.297737Z"
    }
   },
   "outputs": [],
   "source": [
    "class PLModel(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self, \n",
    "        model: nn.Module,\n",
    "        featurizer: nn.Module,\n",
    "        inverse_featurizer: nn.Module,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # featurizers \n",
    "        self.featurizer = featurizer\n",
    "        self.inverse_featurizer = inverse_featurizer\n",
    "                \n",
    "        # model\n",
    "        self.model = model\n",
    "        \n",
    "        # losses\n",
    "        self.mae_specR = nn.L1Loss() \n",
    "        self.mae_specI = nn.L1Loss() \n",
    "        self.mae_time = nn.L1Loss() \n",
    "        \n",
    "        # opts\n",
    "        \n",
    "    \n",
    "    def on_after_batch_transfer(\n",
    "        self, batch, dataloader_idx\n",
    "    ):\n",
    "        for k in batch:\n",
    "            batch[k] = self.featurizer(batch[k])\n",
    "        return batch\n",
    "    \n",
    "    def training_step(\n",
    "        self, batch, batch_idx\n",
    "    ):\n",
    "        mix, tgt = batch['mix'], batch['tgt']\n",
    "        mix = self.model(mix)\n",
    "        loss = self.loss(mix, tgt)\n",
    "        return loss\n",
    "    \n",
    "    def loss(self, mix, tgt):\n",
    "        # frequence domain\n",
    "        lossR = self.mae_specR(mix.real, tgt.real)\n",
    "        lossI = self.mae_specI(mix.imag, tgt.imag)\n",
    "        \n",
    "        # time domain\n",
    "        mix = self.inverse_featurizer(mix)\n",
    "        tgt = self.inverse_featurizer(tgt)\n",
    "        lossT = self.mae_time(mix, tgt) \n",
    "        \n",
    "        # total\n",
    "        loss = lossR + lossI + lossT\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(\n",
    "            self.parameters(), \n",
    "            lr=1e-3\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47720803",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-19T14:03:40.390931Z",
     "start_time": "2023-02-19T14:03:40.304944Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/amanturamatov/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
     ]
    }
   ],
   "source": [
    "plmodel = PLModel(\n",
    "    model, \n",
    "    featurizer,\n",
    "    inverse_featurizer\n",
    ")\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"cpu\",\n",
    "    devices=1,\n",
    "    fast_dev_run=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18bd2557",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-19T14:03:45.102660Z",
     "start_time": "2023-02-19T14:03:40.504835Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name               | Type               | Params\n",
      "----------------------------------------------------------\n",
      "0 | featurizer         | Spectrogram        | 0     \n",
      "1 | inverse_featurizer | InverseSpectrogram | 0     \n",
      "2 | model              | BandSplitRNN       | 11.7 M\n",
      "3 | mae_specR          | L1Loss             | 0     \n",
      "4 | mae_specI          | L1Loss             | 0     \n",
      "5 | mae_time           | L1Loss             | 0     \n",
      "----------------------------------------------------------\n",
      "11.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.7 M    Total params\n",
      "46.687    Total estimated model params size (MB)\n",
      "/Users/amanturamatov/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff6311210e8d43e79a71b94e1cb93ee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Users/amanturamatov/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/Users/amanturamatov/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Users/amanturamatov/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Users/amanturamatov/PythonProjects/projects/SourceSeparationBandSplitRNN/notebooks/../src/data/dataset.py\", line 67, in __getitem__\n    mix, tgt = self.prepare_fragments(\n  File \"/Users/amanturamatov/PythonProjects/projects/SourceSeparationBandSplitRNN/notebooks/../src/data/dataset.py\", line 54, in prepare_fragments\n    tgt_frags, mask = self.sad(tgt_audio)\n  File \"/Users/amanturamatov/PythonProjects/projects/SourceSeparationBandSplitRNN/notebooks/../src/data/preprocessing.py\", line 95, in __call__\n    y_salient = self.calculate_salient(y, segment_saliency_mask)\n  File \"/Users/amanturamatov/PythonProjects/projects/SourceSeparationBandSplitRNN/notebooks/../src/data/preprocessing.py\", line 73, in calculate_salient\n    y = y[:, mask, ...].view(C, D1, D2*D3)\nRuntimeError: shape '[2, 78, 264600]' is invalid for input of size 31752000\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mplmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:608\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[1;32m    606\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_unwrap_optimized(model)\n\u001B[1;32m    607\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39m_lightning_module \u001B[38;5;241m=\u001B[39m model\n\u001B[0;32m--> 608\u001B[0m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    609\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\n\u001B[1;32m    610\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:38\u001B[0m, in \u001B[0;36m_call_and_handle_interrupt\u001B[0;34m(trainer, trainer_fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m     36\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher\u001B[38;5;241m.\u001B[39mlaunch(trainer_fn, \u001B[38;5;241m*\u001B[39margs, trainer\u001B[38;5;241m=\u001B[39mtrainer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     37\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 38\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrainer_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n\u001B[1;32m     41\u001B[0m     trainer\u001B[38;5;241m.\u001B[39m_call_teardown_hook()\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:650\u001B[0m, in \u001B[0;36mTrainer._fit_impl\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[1;32m    643\u001B[0m ckpt_path \u001B[38;5;241m=\u001B[39m ckpt_path \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresume_from_checkpoint\n\u001B[1;32m    644\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ckpt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39m_set_ckpt_path(\n\u001B[1;32m    645\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn,\n\u001B[1;32m    646\u001B[0m     ckpt_path,  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[1;32m    647\u001B[0m     model_provided\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    648\u001B[0m     model_connected\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    649\u001B[0m )\n\u001B[0;32m--> 650\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    652\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstopped\n\u001B[1;32m    653\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1112\u001B[0m, in \u001B[0;36mTrainer._run\u001B[0;34m(self, model, ckpt_path)\u001B[0m\n\u001B[1;32m   1108\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39mrestore_training_state()\n\u001B[1;32m   1110\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39mresume_end()\n\u001B[0;32m-> 1112\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_stage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1114\u001B[0m log\u001B[38;5;241m.\u001B[39mdetail(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: trainer tearing down\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1115\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_teardown()\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1191\u001B[0m, in \u001B[0;36mTrainer._run_stage\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1189\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredicting:\n\u001B[1;32m   1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_predict()\n\u001B[0;32m-> 1191\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1214\u001B[0m, in \u001B[0;36mTrainer._run_train\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1211\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit_loop\u001B[38;5;241m.\u001B[39mtrainer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\n\u001B[1;32m   1213\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mset_detect_anomaly(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_detect_anomaly):\n\u001B[0;32m-> 1214\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py:199\u001B[0m, in \u001B[0;36mLoop.run\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    197\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    198\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_start(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 199\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madvance\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    200\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_end()\n\u001B[1;32m    201\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_restarting \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:267\u001B[0m, in \u001B[0;36mFitLoop.advance\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    265\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_fetcher\u001B[38;5;241m.\u001B[39msetup(dataloader, batch_to_device\u001B[38;5;241m=\u001B[39mbatch_to_device)\n\u001B[1;32m    266\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_training_epoch\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 267\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mepoch_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_data_fetcher\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py:199\u001B[0m, in \u001B[0;36mLoop.run\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    197\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    198\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_start(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 199\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madvance\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    200\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_end()\n\u001B[1;32m    201\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_restarting \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py:187\u001B[0m, in \u001B[0;36mTrainingEpochLoop.advance\u001B[0;34m(self, data_fetcher)\u001B[0m\n\u001B[1;32m    185\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_fetcher, DataLoaderIterDataFetcher):\n\u001B[1;32m    186\u001B[0m     batch_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_idx \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m--> 187\u001B[0m     batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdata_fetcher\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    188\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    189\u001B[0m     batch_idx, batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(data_fetcher)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/pytorch_lightning/utilities/fetching.py:184\u001B[0m, in \u001B[0;36mAbstractDataFetcher.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    183\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__next__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m--> 184\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetching_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/pytorch_lightning/utilities/fetching.py:265\u001B[0m, in \u001B[0;36mDataFetcher.fetching_function\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    262\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdone:\n\u001B[1;32m    263\u001B[0m     \u001B[38;5;66;03m# this will run only when no pre-fetching was done.\u001B[39;00m\n\u001B[1;32m    264\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 265\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fetch_next_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataloader_iter\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    266\u001B[0m         \u001B[38;5;66;03m# consume the batch we just fetched\u001B[39;00m\n\u001B[1;32m    267\u001B[0m         batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatches\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/pytorch_lightning/utilities/fetching.py:280\u001B[0m, in \u001B[0;36mDataFetcher._fetch_next_batch\u001B[0;34m(self, iterator)\u001B[0m\n\u001B[1;32m    278\u001B[0m start_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_fetch_start()\n\u001B[1;32m    279\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 280\u001B[0m     batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    281\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    282\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stop_profiler()\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/pytorch_lightning/trainer/supporters.py:569\u001B[0m, in \u001B[0;36mCombinedLoaderIterator.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    563\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__next__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    564\u001B[0m     \u001B[38;5;124;03m\"\"\"Fetches the next batch from multiple data loaders.\u001B[39;00m\n\u001B[1;32m    565\u001B[0m \n\u001B[1;32m    566\u001B[0m \u001B[38;5;124;03m    Returns:\u001B[39;00m\n\u001B[1;32m    567\u001B[0m \u001B[38;5;124;03m        a collections of batch data\u001B[39;00m\n\u001B[1;32m    568\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 569\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest_next_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloader_iters\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/pytorch_lightning/trainer/supporters.py:581\u001B[0m, in \u001B[0;36mCombinedLoaderIterator.request_next_batch\u001B[0;34m(loader_iters)\u001B[0m\n\u001B[1;32m    571\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[1;32m    572\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrequest_next_batch\u001B[39m(loader_iters: Union[Iterator, Sequence, Mapping]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    573\u001B[0m     \u001B[38;5;124;03m\"\"\"Return the batch of data from multiple iterators.\u001B[39;00m\n\u001B[1;32m    574\u001B[0m \n\u001B[1;32m    575\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    579\u001B[0m \u001B[38;5;124;03m        Any: a collections of batch data\u001B[39;00m\n\u001B[1;32m    580\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 581\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mapply_to_collection\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloader_iters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mIterator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/lightning_utilities/core/apply_func.py:47\u001B[0m, in \u001B[0;36mapply_to_collection\u001B[0;34m(data, dtype, function, wrong_dtype, include_none, *args, **kwargs)\u001B[0m\n\u001B[1;32m     45\u001B[0m \u001B[38;5;66;03m# Breaking condition\u001B[39;00m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, dtype) \u001B[38;5;129;01mand\u001B[39;00m (wrong_dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, wrong_dtype)):\n\u001B[0;32m---> 47\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m elem_type \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtype\u001B[39m(data)\n\u001B[1;32m     51\u001B[0m \u001B[38;5;66;03m# Recursively apply to collection items\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    625\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    626\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    627\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 628\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    629\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    630\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    631\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    632\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1333\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1331\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1332\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_task_info[idx]\n\u001B[0;32m-> 1333\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_process_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1359\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._process_data\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m   1357\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_try_put_index()\n\u001B[1;32m   1358\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, ExceptionWrapper):\n\u001B[0;32m-> 1359\u001B[0m     \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreraise\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1360\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/torch/_utils.py:543\u001B[0m, in \u001B[0;36mExceptionWrapper.reraise\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    539\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m    540\u001B[0m     \u001B[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001B[39;00m\n\u001B[1;32m    541\u001B[0m     \u001B[38;5;66;03m# instantiate since we don't know how to\u001B[39;00m\n\u001B[1;32m    542\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m--> 543\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exception\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Users/amanturamatov/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/Users/amanturamatov/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Users/amanturamatov/opt/anaconda3/envs/SourceSeparationBandSplitRNN/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Users/amanturamatov/PythonProjects/projects/SourceSeparationBandSplitRNN/notebooks/../src/data/dataset.py\", line 67, in __getitem__\n    mix, tgt = self.prepare_fragments(\n  File \"/Users/amanturamatov/PythonProjects/projects/SourceSeparationBandSplitRNN/notebooks/../src/data/dataset.py\", line 54, in prepare_fragments\n    tgt_frags, mask = self.sad(tgt_audio)\n  File \"/Users/amanturamatov/PythonProjects/projects/SourceSeparationBandSplitRNN/notebooks/../src/data/preprocessing.py\", line 95, in __call__\n    y_salient = self.calculate_salient(y, segment_saliency_mask)\n  File \"/Users/amanturamatov/PythonProjects/projects/SourceSeparationBandSplitRNN/notebooks/../src/data/preprocessing.py\", line 73, in calculate_salient\n    y = y[:, mask, ...].view(C, D1, D2*D3)\nRuntimeError: shape '[2, 78, 264600]' is invalid for input of size 31752000\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(\n",
    "    plmodel, \n",
    "    train_dataloaders=train_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5bbc06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
